Some ideas about refactoring of the rendering module

The goal of this refactoring is to:

  * simplify the code
  * improve the design of how data is associated to a template
  * make it very easy to dynamically change the size of datasets
  * have an independent module that does not depend on PyOpenGL and that can
    be used for the high-level interface and for the WebGL version

A few new abstraction layers are introduced to decouple between the logic
of the scene, the datasets, the templates, the data, and the actual
rendering process. This way, the same logic can be used for the PyOpenGL
renderer, and the Javascript webgl renderer (in this case, the whole logic
is serialized and sent as text to the javascript renderer).

New features:
  * index buffers
  * change the size of the data dynamically
  * use the same buffer in different templates
  * new abstraction layer (Scene) that can be serialized and that can be used
    in javascript with a WebGL renderer, or any other renderer
    
Definitions
-----------
    
A scene is defined by a set of datasets, and a data holder, containing data
associated to the templates' fields.

A dataset is defined by a template.
  
A template is defined by a set of variables, and a shader generator which
creates vertex and fragment shader codes from the template parameters.
  
A variable is defined by:

  * its type: attribute, uniform, texture, or varying.
  * whether it's a float or an int,
  * its dimension (scalar or vector of size 2 to 4)
  * its size if it's an array

A template can be parametrized, i.e. can have some parameters that depend
on the data (like the size of some uniforms or the dimension of some
attributes).


Needs for the high-level Python interface
-----------------------------------------

This pylab-like interface can be used in Python and in the IPython notebook.
In the latter case, the dependency to PyOpenGL should not be necessary, since
the whole rendering process will be done by WebGL.

The high-level commands yield a combination of datasets with well-defined
templates and data (and full shader codes, that may be customized according
to what the renderer will be in the next step).

Then, there's a renderer object which takes this information and calls the 
OpenGL-related functions to:
  
  * compile the shaders
  * initialize the rendering engine
  * upload the data
  * render the scene
  

The DataHolder holds data related to a template, including the size.

dataset = template + dataholder

Scene = set of datasets


A Scene is described in PaintManager.initialize()
which calls PaintManager.create_dataset().
This method defines the template and all the data fields associated to it.

PaintManager.add_scene(PlotScene, x=..., y=..., color=..., )


Scene.__init__(**kwargs)
generates a set of datasets with templates and dataholders
it should contain mostly dictionaries with serializable data (except data which
are Numpy arrays)

Then a SceneSerializer serializes it (eg binary data => base64)


plot(x, y, '-o')

        ||
        \/

PlotScene object with:
    dataset1 (name)
        PlotTemplate, LineStrip, vertex_shader, fragment_shader...
        DataHolder
    dataset2 (name)
        PlotTemplate, Points, vertex_shader, fragment_shader...
        DataHolder
        
        
The PaintManager defines a unique scene with create_dataset and set_data.
But there are predefined scenes with some input parameters/data that can be
directly added to the paint manager, which "add_scene". Scenes are also
useful for the high-level interface, they offer a higher level of
abstraction for defining a plot, that can be complex with multiple plot
types (ie multiple datasets), axes, overlays, text, etc, all of that
in the same scene.
        
        
This object should be fully serializable into a dict (JSON).

        ||
        \/

The renderer takes a scene and renders it (backend).
It can also update data, and the size of each dataset is not fixed.
It can change on updates.

There is a base renderer, and GLRenderer(BaseRenderer).
The GLRenderer is already mostly implemented in PaintManager and DataLoader.
        
Renderer.__init__(scene)
Renderer.initialize(scene)
    initialize the GPU, compile the shaders

Renderer.load_data(dataset=None, **kwargs)
or load_data(dataset=dataset, dataholder=dataholder)
    load data on the GPU for the given dataset

Renderer.paint()
    paint all datasets
    
A Javascript WebGLRenderer will also need to be written (it is already mostly
done, named dataloader for now).



Javascript library
------------------

The WebGLRenderer object needs to be written. It takes a deserialized JSON
Scene object with everything in it (datasets, templates, shader codes, data
as a binary object, etc.) and renders everything within a canvas.
It also implements set_data functions, which are called by the javascript
interaction manager.

There is a SceneDeserializer object which takes a serialized version of the scene
and returns a javascript object with binary data.




Example of the expected JSON serialization of a GraphScene
----------------------------------------------------------

### SCENE

{templates: [
    {
     name: ...,
     size: 100,
     primitive_type: Points,
     fields: [
        {name: position,
         id: node_position,
         vartype: float,
         ndim: 2,
         shader_type: attribute,
         data: BASE64ENCODEDSTRING,
        },
        ...
     ],
     vertex_shader: "...",
     fragment_shader: "...",
     },
    {name: ...,
     size: 300,
     primitive_type: Lines,
     fields: [
        {name: position,
         ref: 'node_position'},
        {name: edge_indices,
         shader_type: indices,
         data: BASE64ENCODEDSTRING,
        }],
     vertex_shader: "...",
     fragment_shader: "...",
     }
     ],
}

The PaintManager creates a Scene with user-provided data and generates
the shader codes. The output is a Scene.

Then, the renderer takes the Scene as input and renders it. All the information
needed to render anything on the screen is contained in the scene, and
the creation of the buffers, loading data, compiling shaders, etc. happens
using the Scene information.


PaintManager
------------


class GraphEdgeTemplate():
    def initialize(self):
        # This creates a new attribute, but no new buffer is associated to it.
        # Rather, a "edge_position" attribute is expected to exist in the
        # Scene, and that same buffer will be used by the Renderer.
        self.add_attribute("position", ref="edge_position")
        self.add_indices("edge", data=np.arange(N, dtype=np.int32))

        
create_dataset ==> add_template

def initialize(self, **kwargs):
    self.add_template(GraphNodeTemplate, color=..., position=...)
    self.add_template(GraphEdgeTemplate, color=...)

At the end of initialize(), a Scene object is created.



TODO
----

  * [DONE] Write a Scene object example (Graph example) as a Python dict
  * [DONE] Write a GLRenderer class that takes this Scene dict as input, and
    display it on screen. It should be as standalone as possible with respect
    to the rest of Galry's code.
  * [DONE] Write a new PaintTemplate class that creates a template dynamically. The
    size should not be a parameter of the template. There should be methods
    to generate the shader codes.
  * [DONE] Write a new PaintManager class that creates a Scene object dynamically,
    with add_template and set_data methods.

  * [DONE] Update all templates
  * [WIP] Integrate the new version in the code
    
  * Write the SceneSerializer and SceneDeserializer in Python.  
  * Write a WebGLRenderer class in Javascript, as a standalone Javascript 
    object, in a standalone HTML page.
  * Write the SceneDeserializer in Javascript.


Dataset/template ====> VISUAL
